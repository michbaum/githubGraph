{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "peripheral-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from top_github_scraper import (get_top_repo_urls, get_top_repos, get_top_contributors, \n",
    "get_top_user_urls, get_top_users)\n",
    "#import datapane as dp \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from folium import plugins\n",
    "import geopandas\n",
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "from folium.plugins import Search\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "USERNAME = os.getenv(\"GITHUB_USERNAME\")\n",
    "TOKEN = os.getenv(\"GITHUB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "supported-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"data science\",\"api\"]\n",
    "github_topics = ['3D','Algorithm','Android','API','Arduino','Atom','aws','azure','bash','bootstrap','chrome','compiler','crytocurrency','data structures','database','data visualization','deep learning','data science','deployment','flask','front end','git','google','iOS','json','library','machine learning','macOS','mobile','modeling','natural language processing','neural network','operating system','parsing','software','server','virtual reality','windows']\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ignored-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(keyword, stop=10):\n",
    "    repos = get_repo_urls(keyword, stop=stop)\n",
    "    \n",
    "    all_repo_info = dict()\n",
    "    info_to_scrape = ['name',\"stargazers_count\", \"forks_count\", 'subscribers_count', 'topics', 'language', 'created_at','updated_at']\n",
    "    repo_info = None\n",
    "    for repo in tqdm(repos,desc=\"Scraping top repo info...\"):\n",
    "        repo_url = repo\n",
    "        repo_info_url = f\"https://api.github.com/repos{repo_url}\"\n",
    "        if repo_info and repo_info.status_code == 429:\n",
    "            time.sleep(30)\n",
    "        repo_info = requests.get(repo_info_url, auth=(USERNAME, TOKEN))\n",
    "        repo_info = repo_info.json()\n",
    "        repo_name = repo_info['id']\n",
    "        repo_important_info = {}\n",
    "        for info in info_to_scrape:\n",
    "            repo_important_info[info] = repo_info[info]\n",
    "        repo_important_info['url'] = repo_url\n",
    "        repo_important_info['search_word'] = keyword\n",
    "        all_repo_info[repo_name] = repo_important_info\n",
    "    repo_df = pd.DataFrame.from_dict(all_repo_info, orient='index', columns=info_to_scrape+['url','search_word'])\n",
    "    return repo_df\n",
    "\n",
    "def all_repo_info(keywords, stop=10):\n",
    "    repo_df = pd.DataFrame(columns=['name',\"stargazers_count\", \"forks_count\", 'subscribers_count', 'topics', 'language', 'created_at','updated_at','url','search_word'])\n",
    "    for k in keywords:\n",
    "        new_repo = get_repo_info(k, stop=stop)\n",
    "        print(k,len(new_repo.index))\n",
    "        repo_df = pd.concat([repo_df,new_repo])\n",
    "        repo_df.to_csv('most_updated_repo_info_stop25to75.csv')\n",
    "    return repo_df\n",
    "            \n",
    "\n",
    "def topic_relationship_table(repo_df):\n",
    "    id_list = []\n",
    "    topic_list = []\n",
    "    for i in repo_df.index:\n",
    "        topics = repo_df.loc[i,'topics']\n",
    "        for t in topics:\n",
    "            id_list.append(i)\n",
    "            topic_list.append(t)\n",
    "    df = pd.DataFrame({'id':id_list,'topic':topic_list})\n",
    "    return df\n",
    "\n",
    "\n",
    "SCRAPE_CLASS = {'Users': 'mr-1', 'Repositories': \"v-align-middle\"}\n",
    "TYPE = 'Repositories'\n",
    "def get_repo_urls(keyword, stop=10):\n",
    "    urls = []\n",
    "    page = None\n",
    "    for page_num in tqdm(range(25, stop),desc=\"Scraping top GitHub URLs...\"):\n",
    "        keyword_no_space = (\"+\").join(keyword.split(\" \"))\n",
    "        url = f\"https://github.com/search?o=desc&p={str(page_num)}&q={keyword_no_space}&s=&type={TYPE}\"\n",
    "        if page and page.status_code == 429:\n",
    "            time.sleep(60)\n",
    "        page = requests.get(url, headers={'User-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.4 Safari/605.1.15'})\n",
    "        if page.status_code == 429:\n",
    "            time.sleep(60)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        a_tags = soup.find_all(\"a\", class_=SCRAPE_CLASS[TYPE])\n",
    "        new_urls = [a_tag.get(\"href\") for a_tag in a_tags]\n",
    "        urls.extend(new_urls)\n",
    "        time.sleep(5)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "identified-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_contributors(repo_url, repo_contributor_rel, repo_id, contributors_set,n_contributors=10):\n",
    "    contributor_url = (f\"https://api.github.com/repos{repo_url}/contributors\")\n",
    "    contributor_page = requests.get(contributor_url, auth=(USERNAME, TOKEN))\n",
    "    while contributor_page.status_code == 403:\n",
    "        print('Sleeping')\n",
    "        time.sleep(1500)\n",
    "        contributor_page = requests.get(contributor_url, auth=(USERNAME, TOKEN))\n",
    "    all_contributors = dict()\n",
    "    if contributor_page.status_code != 204:\n",
    "        if contributor_page.status_code == 403:\n",
    "            raise Exception('This is the exception you expect to handle')\n",
    "        contributor_page = contributor_page.json()\n",
    "        max_n_top_contributors = min(len(contributor_page),n_contributors)\n",
    "\n",
    "        profile=None\n",
    "        profile_features = [\"login\",\"url\",\"type\",\"name\",\"company\",\"location\",\"hireable\",\"bio\",\"public_repos\",\"public_gists\",\"followers\",\"following\",\"created_at\"]\n",
    "        if max_n_top_contributors>0 and type(contributor_page)==list:\n",
    "            for n in range(max_n_top_contributors):\n",
    "                contributor = contributor_page[n]\n",
    "                repo_contributor_rel.add((repo_id, contributor[\"login\"], contributor[\"contributions\"]))\n",
    "                if contributor[\"login\"] not in contributors_set and contributor[\"contributions\"]>10:\n",
    "                    contributors_set.add(contributor[\"login\"])\n",
    "                    if profile and profile.status_code == 429:\n",
    "                        time.sleep(30)\n",
    "                    profile = requests.get(contributor[\"url\"], auth=(USERNAME, TOKEN),headers=headers)\n",
    "                    all_contributors[contributor[\"login\"]] = {key: val for key, val in profile.json().items() if key in profile_features}\n",
    "                    if profile and profile.status_code == 429:\n",
    "                        time.sleep(30)\n",
    "    return pd.DataFrame.from_dict(all_contributors,orient='index')\n",
    "\n",
    "def get_all_contributors(repos,repo_contributor_rel,contributors_set,n_contributors=10):\n",
    "    contributor_df = pd.DataFrame(columns=[\"login\",\"url\",\"type\",\"name\",\"company\",\"location\",\"hireable\",\"bio\",\"public_repos\",\"public_gists\",\"followers\",\"following\",\"created_at\"])\n",
    "    for url,r_id in tqdm(repos,desc=\"Scraping top contributors info...\"):\n",
    "        new_contributors = get_repo_contributors(url, repo_contributor_rel, r_id, contributors_set,n_contributors=n_contributors)\n",
    "        #print(url,len(new_contributors.index))\n",
    "        contributor_df = pd.concat([contributor_df,new_contributors]).drop_duplicates()\n",
    "        contributor_df.to_csv(f'most_updated_{n_contributors}_contributor_info_stop75.csv')\n",
    "        pd.DataFrame(repo_contributor_rel, columns=['Repo','Contributor','Contributions']).sort_values('Repo').to_csv('repo_contributor_relationship_table_stop75.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "solid-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = pd.read_csv('repo_info_stop75.csv', index_col=0)\n",
    "repo_contributor_rel = set()\n",
    "c = pd.read_csv('most_updated_10_contributor_info_2.csv', index_col=0)\n",
    "contributors = set(c.index)\n",
    "del c \n",
    "repos_zip = list(zip(list(repos['url']),list(repos.index)))[23896:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "civil-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pd.read_csv('repo_contributor_relationship_table_2.csv',index_col=0)\n",
    "c2 = pd.read_csv('repo_contributor_relationship_table_next1056.csv',index_col=0)\n",
    "c3 = pd.read_csv('repo_contributor_relationship_table_next818.csv',index_col=0)\n",
    "c4 = pd.read_csv('repo_contributor_relationship_table_next2122.csv',index_col=0)\n",
    "c6 = pd.read_csv('repo_contributor_relationship_table_next1978.csv',index_col=0)\n",
    "c7 = pd.read_csv('repo_contributor_relationship_table_next3079.csv',index_col=0)\n",
    "c8 = pd.read_csv('repo_contributor_relationship_table_next6818.csv',index_col=0)\n",
    "c5 = pd.read_csv('repo_contributor_relationship_table_stop75.csv',index_col=0)\n",
    "pd.concat([c1,c2,c3,c4,c5,c6,c7,c8]).drop_duplicates().to_csv('repo_contributor_relationship_table_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "steady-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top contributors info...: 100%|██████████| 311/311 [02:12<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "get_all_contributors(repos_zip,repo_contributor_rel,contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "behind-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:36<00:00, 11.52s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:09<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:42<00:00, 11.65s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:09<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [11:42<00:00, 14.06s/it]\n",
      "Scraping top repo info...: 100%|██████████| 430/430 [01:06<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:45<00:00, 11.70s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:10<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API 391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:36<00:00, 11.53s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:09<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arduino 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:37<00:00, 11.54s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:08<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:37<00:00, 11.55s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:12<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:36<00:00, 11.53s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:17<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:36<00:00, 11.52s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:07<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [10:37<00:00, 12.74s/it]\n",
      "Scraping top repo info...: 100%|██████████| 440/440 [01:02<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:34<00:00, 11.50s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:35<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrome 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.59s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:35<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiler 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:27<00:00, 11.36s/it]\n",
      "Scraping top repo info...: 100%|██████████| 46/46 [00:10<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crytocurrency 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:43<00:00, 11.67s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:34<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data structures 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:41<00:00, 11.62s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:10<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:38<00:00, 11.57s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:09<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data visualization 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.60s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:34<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep learning 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:41<00:00, 11.63s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:35<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science 446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:41<00:00, 11.62s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:10<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment 445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:38<00:00, 11.57s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:07<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flask 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.58s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:12<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front end 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:46<00:00, 11.74s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:07<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:38<00:00, 11.58s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:22<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google 438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.59s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:36<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iOS 436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:38<00:00, 11.58s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:37<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:44<00:00, 11.69s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:38<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:44<00:00, 11.69s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:35<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.58s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:46<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:41<00:00, 11.62s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:36<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobile 445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [11:40<00:00, 14.00s/it]\n",
      "Scraping top repo info...: 100%|██████████| 430/430 [01:30<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:38<00:00, 11.57s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:38<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:40<00:00, 11.62s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:36<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:38<00:00, 11.57s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:36<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating system 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.60s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:32<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:39<00:00, 11.59s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:36<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "software 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:45<00:00, 11.71s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:36<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [13:36<00:00, 16.32s/it]\n",
      "Scraping top repo info...: 100%|██████████| 410/410 [01:31<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virtual reality 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub URLs...: 100%|██████████| 50/50 [09:40<00:00, 11.61s/it]\n",
      "Scraping top repo info...: 100%|██████████| 450/450 [01:34<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows 449\n"
     ]
    }
   ],
   "source": [
    "info = all_repo_info(github_topics, stop=75)\n",
    "topic_rel = topic_relationship_table(info)\n",
    "topic_rel.to_csv('topic_relationship_table_stop25to75.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-differential",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
